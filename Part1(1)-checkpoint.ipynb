{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9948648,"sourceType":"datasetVersion","datasetId":6117827}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Shallow Neural Network Implementation\n\n## Importing Required Libraries\n\nFirst, import the necessary libraries. Note that in this assignment, you are only allowed to use the libraries provided in the notebook.","metadata":{"id":"mAe8Vr1cIT4u"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"id":"TGq-ZgsQIWEn","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:08.049530Z","iopub.execute_input":"2024-11-19T07:25:08.050021Z","iopub.status.idle":"2024-11-19T07:25:08.529403Z","shell.execute_reply.started":"2024-11-19T07:25:08.049977Z","shell.execute_reply":"2024-11-19T07:25:08.528197Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Dataset\n\nIn this exercise, we will use the simple yet famous **Pima Indians Diabetes** dataset. This dataset includes information from **768 Native American women** from the Pima tribe, collected to examine the risk factors for developing type 2 diabetes. The data includes age, weight, height, family history of diabetes, blood pressure, blood glucose levels, and other factors.\n\n<center>\n<div style=\"line-height:200%; font-size:medium\">\n    \n| Column | Description |\n|:------:|:-----------:|\n|Pregnancies|Number of pregnancies|\n|Glucose|Blood glucose level (mg/dL)|\n|BloodPressure|Systolic blood pressure (mmHg)|\n|SkinThickness|Skin thickness (mm)|\n|Insulin|Blood insulin level (μU/mL)|\n|BMI|Body mass index (kg/m²)|\n|DiabetesPedigreeFunction|Function representing family history of diabetes|\n|Age|Age of the woman (years)|\n|Outcome|Non-diabetic (0) or diabetic (1)|\n\n</div>\n</center>\n\n### Reading the Dataset\n\nFirst, you need to read the dataset file. You can read the training data from the file `diabetes_train.csv` located in the `data` folder and use the samples in it to train the model. The model's performance will be evaluated on `diabetes_test.csv`, which has the same structure as the training data except that the `Outcome` column is removed.","metadata":{"id":"bf_FyNaqIaje"}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/diabetes/diabetes_train.csv\")\ntrain_data.head()","metadata":{"id":"7fYf0j_6Iljd","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:10.789814Z","iopub.execute_input":"2024-11-19T07:25:10.790372Z","iopub.status.idle":"2024-11-19T07:25:10.828581Z","shell.execute_reply.started":"2024-11-19T07:25:10.790317Z","shell.execute_reply":"2024-11-19T07:25:10.827591Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/diabetes/diabetes_test.csv\")\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:11.049427Z","iopub.execute_input":"2024-11-19T07:25:11.049928Z","iopub.status.idle":"2024-11-19T07:25:11.069182Z","shell.execute_reply.started":"2024-11-19T07:25:11.049870Z","shell.execute_reply":"2024-11-19T07:25:11.066776Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6       98             58             33      190  34.0   \n1            9      154             78             30      100  30.9   \n2            6      165             68             26      168  33.6   \n3            1       99             58             10        0  25.4   \n4           10       68            106             23       49  35.5   \n\n   DiabetesPedigreeFunction  Age  \n0                     0.430   43  \n1                     0.164   45  \n2                     0.631   49  \n3                     0.551   21  \n4                     0.285   47  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>98</td>\n      <td>58</td>\n      <td>33</td>\n      <td>190</td>\n      <td>34.0</td>\n      <td>0.430</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>154</td>\n      <td>78</td>\n      <td>30</td>\n      <td>100</td>\n      <td>30.9</td>\n      <td>0.164</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>165</td>\n      <td>68</td>\n      <td>26</td>\n      <td>168</td>\n      <td>33.6</td>\n      <td>0.631</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>99</td>\n      <td>58</td>\n      <td>10</td>\n      <td>0</td>\n      <td>25.4</td>\n      <td>0.551</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>68</td>\n      <td>106</td>\n      <td>23</td>\n      <td>49</td>\n      <td>35.5</td>\n      <td>0.285</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Preprocessing and Feature Engineering\n\nFirst, store the target variable column (`Outcome`) in a separate DataFrame and then remove this column from the `train_data` DataFrame to create the equivalent matrices $X$ and $y$.","metadata":{"id":"mM5Fb_wTIwoy"}},{"cell_type":"code","source":"train_data_outcome = train_data[\"Outcome\"]\ntrain_data = train_data.drop([\"Outcome\"], axis=1)\n\ntrain_data.head()","metadata":{"id":"IgwFWO9DI4Kq","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:14.251241Z","iopub.execute_input":"2024-11-19T07:25:14.251687Z","iopub.status.idle":"2024-11-19T07:25:14.272324Z","shell.execute_reply.started":"2024-11-19T07:25:14.251650Z","shell.execute_reply":"2024-11-19T07:25:14.270867Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  \n0                     0.627   50  \n1                     0.351   31  \n2                     0.672   32  \n3                     0.167   21  \n4                     2.288   33  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"One of the crucial preprocessing steps is feature scaling to a normal distribution, commonly referred to as normalization. Normalization helps reduce significant weight fluctuations and accelerates model convergence. In this assignment, you should normalize each feature so that their mean is `0` and their variance is `1`. This can be done using the following formula:\n\nFor a data series `X = [x_1, x_2, ..., x_n]`, subtract the mean from each data sample (`x_i`) and divide by the standard deviation (sigma) to obtain the normalized data series.\n\n$$ Z = \\frac{x_i - \\bar{x}}{\\sigma} $$\n\n**Note:** Since we only have access to the training data when building the model, use the mean and standard deviation from the training samples to normalize the test samples as well.","metadata":{"id":"k1TOYDG5I5cu"}},{"cell_type":"code","source":"for column in train_data.columns:\n    mean = train_data[column].mean()\n    std = train_data[column].std()\n    train_data[column] = (train_data[column] - mean) / std\n    test_data[column] = (test_data[column] - mean) / std\n\ntrain_data.head()","metadata":{"id":"yJddsz0JI88N","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:24.208306Z","iopub.execute_input":"2024-11-19T07:25:24.208766Z","iopub.status.idle":"2024-11-19T07:25:24.239295Z","shell.execute_reply.started":"2024-11-19T07:25:24.208701Z","shell.execute_reply":"2024-11-19T07:25:24.237980Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n0     0.649833  0.854539       0.166518       0.900880 -0.687695  0.222281   \n1    -0.835754 -1.096441      -0.140758       0.526362 -0.687695 -0.672046   \n2     1.244068  1.938416      -0.243184      -1.283807 -0.687695 -1.093658   \n3    -0.835754 -0.972569      -0.140758       0.151844  0.123855 -0.480405   \n4    -1.132872  0.513891      -1.472290       0.900880  0.762734  1.436011   \n\n   DiabetesPedigreeFunction       Age  \n0                  0.438405  1.443781  \n1                 -0.370035 -0.178571  \n2                  0.570216 -0.093184  \n3                 -0.908995 -1.032441  \n4                  5.303692 -0.007797  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.649833</td>\n      <td>0.854539</td>\n      <td>0.166518</td>\n      <td>0.900880</td>\n      <td>-0.687695</td>\n      <td>0.222281</td>\n      <td>0.438405</td>\n      <td>1.443781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.835754</td>\n      <td>-1.096441</td>\n      <td>-0.140758</td>\n      <td>0.526362</td>\n      <td>-0.687695</td>\n      <td>-0.672046</td>\n      <td>-0.370035</td>\n      <td>-0.178571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.244068</td>\n      <td>1.938416</td>\n      <td>-0.243184</td>\n      <td>-1.283807</td>\n      <td>-0.687695</td>\n      <td>-1.093658</td>\n      <td>0.570216</td>\n      <td>-0.093184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.835754</td>\n      <td>-0.972569</td>\n      <td>-0.140758</td>\n      <td>0.151844</td>\n      <td>0.123855</td>\n      <td>-0.480405</td>\n      <td>-0.908995</td>\n      <td>-1.032441</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.132872</td>\n      <td>0.513891</td>\n      <td>-1.472290</td>\n      <td>0.900880</td>\n      <td>0.762734</td>\n      <td>1.436011</td>\n      <td>5.303692</td>\n      <td>-0.007797</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Next, add a bias term to the DataFrame. To do this, add a column with a value of `1` at the beginning of the dataset.","metadata":{"id":"e81ZduqxI_W1"}},{"cell_type":"code","source":"train_bias = np.array(1)\ntrain_data.insert(loc=0, column=\"train_bias\", value=train_bias)\n\ntest_bias = np.array(1)\ntest_data.insert(loc=0, column=\"test_bias\", value=test_bias)\n\ntrain_data.head()","metadata":{"id":"CXFJbXe0JDzL","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:25:33.510666Z","iopub.execute_input":"2024-11-19T07:25:33.511587Z","iopub.status.idle":"2024-11-19T07:25:33.530750Z","shell.execute_reply.started":"2024-11-19T07:25:33.511528Z","shell.execute_reply":"2024-11-19T07:25:33.529520Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   train_bias  Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin  \\\n0           1     0.649833  0.854539       0.166518       0.900880 -0.687695   \n1           1    -0.835754 -1.096441      -0.140758       0.526362 -0.687695   \n2           1     1.244068  1.938416      -0.243184      -1.283807 -0.687695   \n3           1    -0.835754 -0.972569      -0.140758       0.151844  0.123855   \n4           1    -1.132872  0.513891      -1.472290       0.900880  0.762734   \n\n        BMI  DiabetesPedigreeFunction       Age  \n0  0.222281                  0.438405  1.443781  \n1 -0.672046                 -0.370035 -0.178571  \n2 -1.093658                  0.570216 -0.093184  \n3 -0.480405                 -0.908995 -1.032441  \n4  1.436011                  5.303692 -0.007797  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_bias</th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.649833</td>\n      <td>0.854539</td>\n      <td>0.166518</td>\n      <td>0.900880</td>\n      <td>-0.687695</td>\n      <td>0.222281</td>\n      <td>0.438405</td>\n      <td>1.443781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.835754</td>\n      <td>-1.096441</td>\n      <td>-0.140758</td>\n      <td>0.526362</td>\n      <td>-0.687695</td>\n      <td>-0.672046</td>\n      <td>-0.370035</td>\n      <td>-0.178571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.244068</td>\n      <td>1.938416</td>\n      <td>-0.243184</td>\n      <td>-1.283807</td>\n      <td>-0.687695</td>\n      <td>-1.093658</td>\n      <td>0.570216</td>\n      <td>-0.093184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-0.835754</td>\n      <td>-0.972569</td>\n      <td>-0.140758</td>\n      <td>0.151844</td>\n      <td>0.123855</td>\n      <td>-0.480405</td>\n      <td>-0.908995</td>\n      <td>-1.032441</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-1.132872</td>\n      <td>0.513891</td>\n      <td>-1.472290</td>\n      <td>0.900880</td>\n      <td>0.762734</td>\n      <td>1.436011</td>\n      <td>5.303692</td>\n      <td>-0.007797</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Before designing and training the model, convert the datasets from DataFrames to NumPy arrays. Therefore, in this step, convert the DataFrames `train_data` and `train_data_outcome` to NumPy arrays. Additionally, use the `train_test_split` function to split this dataset into training and validation sets with a ratio of `0.2`.\n\n**Note:** According to previous lectures, each **row** of the input matrix represents a **feature**, and each **column** represents a **sample**. Therefore, you need to transpose the feature matrix. This step should also be applied to the target variable (`train_data_outcome`).","metadata":{"id":"atOwCWIKJEhG"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_validation, y_train, y_validation = train_test_split(train_data, train_data_outcome, test_size=0.2)\n\nX_train = X_train.T\nX_validation = X_validation.T\ny_train = y_train.T\ny_validation = y_validation.T\ntest_data_numpy = test_data.T","metadata":{"id":"Moa4vZOHJHx1","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:28:44.542465Z","iopub.execute_input":"2024-11-19T07:28:44.542872Z","iopub.status.idle":"2024-11-19T07:28:44.549695Z","shell.execute_reply.started":"2024-11-19T07:28:44.542836Z","shell.execute_reply":"2024-11-19T07:28:44.548054Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"To ensure the correctness of input and output settings, running the next cell should produce the following output:\n\n```\nX_train.shape:(9, 534), y_train.shape:(534,)\nX_validation.shape:(9, 134), y_validation.shape:(134,)\ntest_data_numpy.shape:(9, 100)\n```","metadata":{"id":"sdHMNuKjJLtk"}},{"cell_type":"code","source":"print(f'X_train.shape:{X_train.shape}, y_train.shape:{y_train.shape}')\nprint(f'X_validation.shape:{X_validation.shape}, y_validation.shape:{y_validation.shape}')\nprint(f'test_data_numpy.shape:{test_data_numpy.shape}')","metadata":{"id":"N3W2d5xQJMT1","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:28:51.530085Z","iopub.execute_input":"2024-11-19T07:28:51.530484Z","iopub.status.idle":"2024-11-19T07:28:51.536610Z","shell.execute_reply.started":"2024-11-19T07:28:51.530448Z","shell.execute_reply":"2024-11-19T07:28:51.535344Z"}},"outputs":[{"name":"stdout","text":"X_train.shape:(9, 534), y_train.shape:(534,)\nX_validation.shape:(9, 134), y_validation.shape:(134,)\ntest_data_numpy.shape:(9, 100)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Modeling\n\nNow that the data is processed and ready, it's time for the main part—building the model. You are required to implement a simple shallow neural network using gradient descent from scratch. We will explain each component of this model step by step to guide you through its implementation.\n\nThis model is a shallow neural network with one hidden layer containing `1000` neurons. The activation function for this layer is the Rectified Linear Unit (ReLU), which you are familiar with from the activation function lectures. The activation function for the output layer is the sigmoid function. Note that the required formulas for each part are provided below. We have also implemented the two activation functions for you.\n\n```python\nsigmoid_Z = 1 / (1 + np.exp(-Z))\n```\n\n```python\nReLU_Z = np.maximum(0, Z)\n```\n\n**Note:** Only use the NumPy library for mathematical operations and computations, and define your lists as NumPy arrays.","metadata":{"id":"D5I0--wwJ83T"}},{"cell_type":"markdown","source":"### Reminder: Sigmoid Function\n\n| Sigmoid Function | Derivative of Sigmoid Function |\n| :---: | :--: |\n| $f(z) = \\frac{1}{1 + e^{-z}}$ | $f'(z) = f(z)(1-f(z))$ |","metadata":{"id":"qvPJycbcKTGh"}},{"cell_type":"markdown","source":"### Reminder: ReLU Activation Function\n\n| ReLU Function  | Derivative of ReLU Function  |\n| :---: | :--: |\n|$$f(z) = \\begin{cases} 0 & \\text{if } z < 0 \\\\ z & \\text{if } z \\geq 0\\end{cases}$$|$$f'(z) = \\begin{cases} 0 & \\text{if } z < 0 \\\\ 1 & \\text{if } z \\geq 0\\end{cases}$$|","metadata":{"id":"rPw_rHtcKUmZ"}},{"cell_type":"markdown","source":"### `Model` Class Construction\n\nCreate a class named `Model` that contains the following three methods. We will explain each method in detail below.","metadata":{"id":"C2yIwnRmKZMx"}},{"cell_type":"code","source":"def __init__(self)\ndef predict(self, inputs)\ndef update_weights_for_one_epoch(self, inputs, outputs, learning_rate)\ndef fit(self, inputs, outputs, learning_rate, epochs=64)","metadata":{"id":"CI6f_Ax3KgMm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### `__init__` Method\n\nIn the `__init__(self)` method, initialize the weights of the hidden and output layers (`w1` and `w2`) randomly with a mean of `0` and a standard deviation of `0.01`. You can use the `np.random.randn` function for this purpose. Note that `np.random.randn` generates random numbers with a mean of `0` and a standard deviation of `1`, so you need to adjust these values accordingly to meet the problem requirements.","metadata":{"id":"SLqB5ZibKivK"}},{"cell_type":"markdown","source":"#### `predict` Method\n\nThe `predict(self, inputs)` method takes the inputs and sequentially returns the outputs of both layers (`A_1` and `A_2`). Implement this process according to the following formulas:\n\n$$Z^{[1]}=W^{[1]}.X$$\n$$A^{[1]}=ReLU(Z^{[1]})$$\n$$Z^{[2]}=W^{[2]}A^{[1]}$$\n$$A^{[2]}=\\sigma(Z^{[2]})=\\frac{1}{1+e^{-Z^{[2]}}}=Y_{pred}$$\n\n**Hint:** To perform matrix multiplication between two matrices, use the `arr1.dot(arr2)` function. For example, the formula $Z^{[1]}=W^{[1]}X$ corresponds to `W_1.dot(X)` in Python. Alternatively, you can use the `@` operator as `W_1 @ X`.","metadata":{"id":"mNjFJpqfKl-o"}},{"cell_type":"markdown","source":"#### `update_weights_for_one_epoch` Method\n\nIn the `update_weights_for_one_epoch(self, inputs, outputs, learning_rate)` method, update the network's weights for one epoch. Note that `learning_rate` is the learning rate or alpha. The required formulas for this section are provided below. In the next chapter, we will explain in detail how to compute them.\n\n**Weight Update for `w2`:**\n\n$$W^{[2]} = W^{[2]} + \\Delta W^{[2]}$$\n$$\\Delta W^{[2]} = - \\alpha \\frac{\\partial cost}{\\partial W^{[2]}}$$\n$$\\frac{\\partial cost}{\\partial W^{[2]}} = \\left(\\frac{-2}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right) \\bullet A^{[1]T}$$\n$$W^{[2]} = W^{[2]} + \\left(\\frac{2 \\alpha}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right) \\bullet A^{[1]T}$$\n\n**Weight Update for `w1`:**\n\n$$W^{[1]} = W^{[1]} + \\Delta W^{[1]}$$\n$$\\Delta W^{[1]} = - \\alpha \\frac{\\partial cost}{\\partial W^{[1]}}$$\n\n$$\\frac{\\partial cost}{\\partial W^{[1]}} = \\left(\\left(\\frac{-2}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right)^T \\bullet W^{[2]}\\right)^T \\odot \\frac{\\partial A^{[1]}}{\\partial Z^{[1]}} \\bullet X^T$$\n\n$$W^{[1]} = W^{[1]} + \\left(\\left(\\frac{2 \\alpha}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right)^T \\bullet W^{[2]}\\right)^T \\odot \\frac{\\partial A^{[1]}}{\\partial Z^{[1]}} \\bullet X^T$$\n\n**Note:** The symbol $\\odot$ represents element-wise multiplication, and the symbol $\\bullet$ represents matrix multiplication.\n\nTo obtain the value of $\\frac{\\partial A^{[1]}}{\\partial Z^{[1]}}$, which is the derivative of the ReLU function, use the following code snippet. This will produce a matrix of the same size as $Z^{[1]}$, composed of `0` and `1`, where cells corresponding to $Z^{[1]} > 0$ will have a value of `1`, and `0` otherwise. Note that although you pass `A_1` as input to this function, it does not affect the output.\n\n```python\nrelu_gradient = np.where(A_1 > 0, 1, 0)\n```\n\n**Important:** Part of $\\Delta W^{[1]}$ is already computed in $\\Delta W^{[2]}$. By storing it, you can avoid redundant calculations.","metadata":{"id":"7_-V2fChKqsT"}},{"cell_type":"markdown","source":"#### `fit` Method\n\nThe `fit(self, inputs, outputs, learning_rate, epochs=64)` method updates the network's weights for the specified number of epochs (`epochs`). You do not need to make any changes to this method; simply use it in the subsequent steps.","metadata":{"id":"QMV3g1W6K0Qy"}},{"cell_type":"markdown","source":"### Model Class Implementation","metadata":{"id":"PJ7Z6vUxK3rW"}},{"cell_type":"code","source":"class Model:\n\n    def __init__(self):\n        self.w1 = np.random.randn(1000, X_train.shape[0]) * 0.01\n        self.w2 = np.random.randn(1, 1000) * 0.01\n\n    def predict(self, inputs):\n        x = inputs\n\n        Z_1 = np.dot(self.w1, x)\n        A_1 = np.maximum(0, Z_1)\n\n        Z_2 = np.dot(self.w2, A_1)\n        A_2 = 1 / (1 + np.exp(-Z_2))\n\n        return A_1, A_2\n\n    def update_weights_for_one_epoch(self, inputs, outputs, learning_rate):\n        x, y_true = inputs, outputs\n        A_1, A_2 = self.predict(inputs)\n\n        n = x.shape[1]\n\n        shared_coefficient = 2 * learning_rate / n * ((y_true - A_2) * A_2 * (1 - A_2))\n        relu_gradient = np.where(A_1 > 0, 1, 0)\n        \n        self.w1 = self.w1 + np.dot(((np.dot(shared_coefficient.T, self.w2)).T * relu_gradient), x.T)\n        self.w2 = self.w2 + np.dot(shared_coefficient, A_1.T)\n\n    def fit(self, inputs, outputs, learning_rate, epochs=64):\n        for i in range(epochs):\n            self.update_weights_for_one_epoch(inputs, outputs, learning_rate)","metadata":{"id":"ukBhc2a7K836","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T08:32:03.627950Z","iopub.execute_input":"2024-11-19T08:32:03.628435Z","iopub.status.idle":"2024-11-19T08:32:03.639356Z","shell.execute_reply.started":"2024-11-19T08:32:03.628400Z","shell.execute_reply":"2024-11-19T08:32:03.637870Z"}},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":"### Training and Evaluation\n\nAfter designing the network structure, you can create an instance of the `Model()` class and then call the `fit` method with appropriate arguments to start training the model. It is recommended to experiment with different learning rates (such as `0.1`, `0.01`, `0.001`, etc.) and different numbers of training epochs, and compare the results on the validation samples.\n\nTo assess the model's accuracy, you can use the `evaluation(model, inputs, outputs)` function.","metadata":{"id":"DhnMZoohK_hP"}},{"cell_type":"code","source":"def evaluation(model, inputs, outputs):\n  _, A_2 = model.predict(inputs)\n  prediction = (A_2 > 0.5)\n  return np.mean(prediction == outputs) * 100\n\nmodel = Model()\nmodel.fit(X_train, y_train.to_numpy().reshape(1, -1), learning_rate = 0.02, epochs = 1000) # TODO\n\n# Model evaluation\nprint(f\"Your model accuracy on the given set: {round(evaluation(model, X_validation, y_validation.to_numpy().reshape(1, -1)), 2)}%\") # TODO","metadata":{"id":"rNZCZNy4LCeJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T08:38:06.392366Z","iopub.execute_input":"2024-11-19T08:38:06.392766Z","iopub.status.idle":"2024-11-19T08:38:29.931918Z","shell.execute_reply.started":"2024-11-19T08:38:06.392730Z","shell.execute_reply":"2024-11-19T08:38:29.930793Z"}},"outputs":[{"name":"stdout","text":"Your model accuracy on the given set: 73.88%\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"## Prediction on Test Data and Output\n\nFinally, you need to compute the model's output for the test samples. First, obtain the model's output on the test data, and then if the model predicts a higher probability that an individual has diabetes (output greater than `0.5`), classify the individual as diabetic; otherwise, classify them as non-diabetic.\n\nTherefore, in the `prediction` variable, which is a NumPy array, you will have `True` and `False` values. Note that this variable will also be evaluated by the grading system.","metadata":{"id":"r1FMFxLLLFko"}},{"cell_type":"code","source":"_, output = model.predict(test_data_numpy) # TODO\nprediction = (output > 0.5)\nprediction","metadata":{"id":"676HkPtxLHs_","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T08:39:04.503574Z","iopub.execute_input":"2024-11-19T08:39:04.503965Z","iopub.status.idle":"2024-11-19T08:39:04.511665Z","shell.execute_reply.started":"2024-11-19T08:39:04.503932Z","shell.execute_reply":"2024-11-19T08:39:04.510565Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"array([[False,  True,  True, False, False,  True, False,  True, False,\n        False, False, False, False,  True, False, False, False, False,\n        False, False, False,  True, False,  True, False,  True, False,\n         True, False, False, False, False, False, False,  True, False,\n        False, False, False, False,  True, False, False, False,  True,\n        False, False,  True,  True, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False,  True, False, False, False, False, False, False, False,\n         True, False, False,  True,  True, False,  True, False,  True,\n        False, False, False, False,  True,  True, False, False, False,\n        False,  True, False,  True, False, False, False, False, False,\n        False]])"},"metadata":{}}],"execution_count":71},{"cell_type":"markdown","source":"## Assignment Grading Procedure\n\nThe accuracy of your model on the test data, specifically the `prediction` variable, will also be evaluated, with a minimum acceptable accuracy of **65%**.\n\nAdditionally, the `test_data` DataFrame will be checked to ensure the correctness of your data normalization process.","metadata":{"id":"4zfxesfSLKmy"}}]}